Confirm Sample Size

Broad search	10	100	1000		10000	100000

Guided search	10k	20k	30k	40k	50k	....100k









#Outlier calculation

Step1: Calculate IQR (Inter quartile range) ~ variation in each quartile

IQR = (Q3-Q1)*1.5 = 6.667


step2:

Q3+IQR = 21.212		# all values above this are outliers

Q1-IQR = 3.433		# all values below this are outliers



Features Selection

1)Retain the most relevant X features from the original dataset using Correlation calc.
2)Missing Value Ratio
3)Remove the columns with low variance
4)High Correlation Filter amongst X features

Features Selection
1)Retain the most relevant X features from the original dataset using Correlation calc.


Correlation	
				Check the relevance between X & y Features
				Understand how much influence each individual X feature has on Y feature
				Correlation between X & Y captures linear-relationship
				Correlation of individual X feature must be calculated against Y feature


Correlation is calculated using r-value / Pearsonr-value 

Pearsonr-value conveys the percentage of correlation between X & Y



====================================================

Pearsonr-value [-1 to 1]

Pearsonr-value = 0.95		X & y are 95% correlated		- strong linear positive trend in data
Pearsonr-value = -0.85		X & y are -85% correlated		- strong linear negative trend in data

Pearsonr-value = 0.08		X & y are 8% correlated		- strong non-linear trend in data

Pearsonr-value

0 to < 0.25			No-linear correlation between X & Y

0.25 to < 0.50		Negligible linear correlation between X & Y

0.50 to < 0.75		Moderate linear correlation between X & Y

> 0.75			Very Strong linear correlation between X & Y




====================================================

Model Implementation

Algorithm that best suite Linear Spread of data

Prefer Choosing X features that are linearly correlated (pos/neg) with Y


When most of the X features (80%) of them fall into "moderate" to "very strong correlation" with Y
we choose Linear Algorithms and discard the other X features that fall into negligible to no correlation range


InputData		X1		X2		X3		X4		X5		X6		X7		X8		X9		X10

Output Data	Y

pearsonr		90%		80%		95%		75%		87%		20%		1%		82%		99%		91%


====================================================================================

InputData		X1		X2		X3		X4		X5		X6		X7		X8		X9		X10

Output Data	Y

pearsonr		10%		18%		95%		5%		7%		20%		1%		12%		19%		11%


Algorithm that best suite Non-Linear Spread of data

Prefer Choosing X features that are NOT linearly correlated (pos/neg) with Y

Whenmost of the X features (80%) of them fall into "negligible" to "no correlation" range with Y
we choose Non-Linear Algorithms and discard the other X features that fall into "moderate" to "very strong correlation" 







====================================================

2)Missing Value Ratio

Missing value == nan

Ratio = NumOfmissingValues/numberOfRows = threshold [>10% or 20%] drop the column



Age		20	21	nan	28	30	nan	20	nan	nan	27	nan

Age		20	21	23	28	30	nan	20	nan	22	27	25

																		Model Implementation

Age		2 nans / 100 rows = 	2%		Replace nans with mean(Age)			Accuracy 92%
Age		5 nans / 100 rows = 	5%		Replace nans with mean(Age)			Accuracy 92%


Threshold 5% > Drop Column


Age		20 nans / 100 rows = 	20%		Replace nans with mean(Age)			Accuracy 89%
Age		60 nans / 100 rows = 	60%		Replace nans with mean(Age)			Accuracy 75%






====================================================

3)Remove the columns with low variance

Age		30	30	30	30	30	30	30	30	30		variance = 0			low variance = 1.90 ~ 0.456

Response	1	1	1	0	1	1	0	1	


====================================================
4)High Correlation Filter amongst X features

		
			WebApp		MobileApp		WebMobileApp

			1			0				0
			0			1				0
			1			1				1


		WeightKg		WeightLBS

		CyclingTime		HeartRate




Machine Learning

1)Data Collection
2)Data Cleaning				remove rows , columns , type cast , calculations .......................
3)Data Exploration
4)Data Preprocessing			Train-Test Split, Encoding , Scaling of values 
5)Model Implementation


SUPERVISED LEARNING				Input Data & Output Data		Remember & Generalize

	Regression			If the value to predict is Continuous

		Linear Regression			Linear Spread of data
		Polynomial Regression		non-Linear Spread of data
		DecisionTree Regressor		non-Linear Spread of data
		RandomForest Regressor		non-Linear Spread of data

	Classification		If the value to predict is Discrete
		
		Logistic Regression
		K-Nearest Neighbours
		Support Vector Machine
		Naive Bayes
		DecisionTree Classifier
		RandomForest Classifier	

UNSUPERVISED LEARNING				Input Data					Remember & Generalize

		Clustering
			K-Means Clustering

REINFORCEMENT LEARNING			Data is feeded on the go		Adaptiveness
		
		Upper Confidence Bound
		Thompsan Sampling

DEEP LEARNING					Input Data & Output Data		Remember & Generalize

		Aritificial Neural Network

Natural Language Processing			Text Preprocessing 








Continuous value prediction , Measure of Model Performance is MSE or RMSE

YrsExp		ActualSal		PredictedSal		Error = diff(actual,predicted) = avg(diff(actual,predicted)^2)

1			10000		10500			-500	
2.5			12000		12000			0
3			15000		20000			-5000
3.5			17000		11000			6000
4			20000		19000			1000
4.5			25000		27000			-2000
											--------------------- Error MSE , number with no units ~ 0
											--------------------- sqrt(MSE) = RMSE with units of data ~ 0
																	Root mean square error



============================================================

Discrete Value Prediction , Measure of Model Performance Accuracy score



Age		ActualReponse		PredictedResponse		Accuracy = 6/9*100 = 66% accurate score

20			0			0
30			1			1
21			0			0
35			1			0
40			1			1
45			1			1
50			0			1
18			0			0
19			1			0

















WinOs		Search for    spyder


MacOs		start terminal	, execute the command		spyder






SUPERVISED LEARNING				Input Data & Output Data		Remember & Generalize

	Regression			If the value to predict is Continuous

		Linear Regression			Linear Spread of data




	y = b0 + b1*X1


	35000	25000	5000*2		
	salary = basePkg + amt *TotalExp
			0yrsExp	(+1yrsExp)


				X_train,y_train
Algorithm1 => y = b0 + b1*X1

sum(y)*sum(x^2) - sum(x)sum(xy)
------------------------------------------b0 = intercept
n*sum(x^2) - sum(x)^2



n*sum(xy) - sum(x)*sum(y)
--------------------------------b1 = slope
n*sum(x^2) - sum(x)^2



Model(YrsExp) =  26816.19224403119 + (9345.94244312*___YrsExp__)

Model(X_test) = _________

Model(9.5) = _________



				X_train,y_train
Algorithm2 => y = sum(y)*sum(x^2) - sum(x)sum(xy)


				X_train,y_train
Algorithm3 => y = n*sum(x^2) - sum(x)^2




student1		randomSplit		Train-Test		RandomStrategy1
student2		randomSplit		Train-Test		RandomStrategy2
student3		randomSplit		Train-Test		RandomStrategy3
student4		randomSplit		Train-Test		RandomStrategy4
student5		randomSplit		Train-Test		RandomStrategy5


random_state = 0 , seed of randomness

student1		randomSplit		Train-Test		RandomStrategy0
student2		randomSplit		Train-Test		RandomStrategy0
student3		randomSplit		Train-Test		RandomStrategy0
student4		randomSplit		Train-Test		RandomStrategy0
student5		randomSplit		Train-Test		RandomStrategy0
student6		randomSplit		Train-Test		RandomStrategy0





In Real-Time

We get the following Data Sets independently Sampled 

1)	Training Set	60%			We train on training data

2)	Validation Set	20%			After training we check how well it performs on the validation set

3)	Testing Set 	20%			When we have final Model (Model that has performed well on both training and validation)
							We evaluate it on the test set to go and get unbiased estimation of its performance



Train Sample


Test Sample1
Test Sample2
Test Sample3
Test Sample4		

































